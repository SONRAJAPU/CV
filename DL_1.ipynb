{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SONRAJAPU/CV/blob/main/DL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoG9bNOseXhR"
      },
      "source": [
        "Sure, here are the steps to implement this project using the CIFAR-10 dataset, ResNet architecture, and FGSM attack:\n",
        "\n",
        "Load the CIFAR-10 dataset and preprocess the data (e.g., normalize the images).\n",
        "Define the ResNet model architecture and train it on the CIFAR-10 dataset. You can use a pre-trained ResNet model if you prefer.\n",
        "\n",
        "Implement the FGSM attack using a library like PyTorch or TensorFlow. FGSM requires calculating the gradient of the loss function with respect to the input and using it to generate adversarial examples by adding a small perturbation to the input.\n",
        "\n",
        "Generate adversarial examples for a subset of the CIFAR-10 dataset using the FGSM attack. You can use different strengths of the attack by adjusting the magnitude of the perturbation.\n",
        "\n",
        "Evaluate the accuracy and loss of the ResNet model on the clean CIFAR-10 dataset and the adversarial examples generated by the FGSM attack.\n",
        "\n",
        "Dissect the ResNet model into multiple components, such as the convolutional layers, the fully connected layers, and the skip connections.\n",
        "\n",
        "Freeze the parameters in each component except for the ones you want to fine-tune for adversarial robustness. For example, you can freeze the parameters in the convolutional layers and the skip connections and fine-tune the fully connected layers.\n",
        "\n",
        "Fine-tune the selected components of the ResNet model using the adversarial examples generated in Step 4. You can use a small learning rate and a few epochs to avoid overfitting.\n",
        "Evaluate the accuracy and loss of the fine-tuned ResNet model on the clean CIFAR-10 dataset and the adversarial examples generated by the FGSM attack.\n",
        "Compare the loss values of each component to understand their contribution to the overall performance drop during adversarial attacks. You can use visualization techniques like heatmaps or saliency maps to visualize the importance of each component in the network's predictions.\n",
        "Analyze the results and draw conclusions about the sensitivity of the ResNet model to adversarial attacks and the contribution of each component to its robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk-Z-7XMekvO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmdlvdYSeoTQ"
      },
      "source": [
        "Load the CIFAR-10 dataset and preprocess the data (e.g., normalize the images). Define the ResNet model architecture and train it on the CIFAR-10 dataset. You can use a pre-trained ResNet model if you prefer. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG9mYYFTetJ_",
        "outputId": "a1606c0f-1ff5-4c40-8462-62a1f5749c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13411516.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 282MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.440\n",
            "[1,   200] loss: 1.011\n",
            "[1,   300] loss: 0.899\n",
            "[2,   100] loss: 0.754\n",
            "[2,   200] loss: 0.707\n",
            "[2,   300] loss: 0.699\n",
            "[3,   100] loss: 0.623\n",
            "[3,   200] loss: 0.610\n",
            "[3,   300] loss: 0.618\n",
            "[4,   100] loss: 0.553\n",
            "[4,   200] loss: 0.567\n",
            "[4,   300] loss: 0.558\n",
            "[5,   100] loss: 0.518\n",
            "[5,   200] loss: 0.504\n",
            "[5,   300] loss: 0.524\n",
            "[6,   100] loss: 0.486\n",
            "[6,   200] loss: 0.489\n",
            "[6,   300] loss: 0.490\n",
            "[7,   100] loss: 0.448\n",
            "[7,   200] loss: 0.442\n",
            "[7,   300] loss: 0.457\n",
            "[8,   100] loss: 0.409\n",
            "[8,   200] loss: 0.433\n",
            "[8,   300] loss: 0.437\n",
            "[9,   100] loss: 0.393\n",
            "[9,   200] loss: 0.402\n",
            "[9,   300] loss: 0.413\n",
            "[10,   100] loss: 0.396\n",
            "[10,   200] loss: 0.375\n",
            "[10,   300] loss: 0.394\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define transforms for the data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                            download=True, transform=transform_train)\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                           download=True, transform=transform_test)\n",
        "\n",
        "# Define the dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Load the pre-trained ResNet model and modify the output layer to fit the CIFAR-10 dataset\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # Get the inputs and labels\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WR7lF1ckZNX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the FGSM attack using a library like PyTorch or TensorFlow. FGSM requires calculating the gradient of the loss function with respect to the input and using it to generate adversarial examples by adding a small perturbation to the input.\n"
      ],
      "metadata": {
        "id": "uhhhWuHNZwOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def fgsm_attack(model, loss, x, y, epsilon):\n",
        "    # Set requires_grad attribute of tensor x\n",
        "    x.requires_grad = True\n",
        "    \n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    \n",
        "    # If the initial prediction is wrong, don't bother attacking\n",
        "    if init_pred.item() != y.item():\n",
        "        return x\n",
        "    \n",
        "    # Calculate the loss\n",
        "    loss = loss(output, y)\n",
        "    \n",
        "    # Zero all existing gradients\n",
        "    model.zero_grad()\n",
        "    \n",
        "    # Calculate gradients of model in backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Collect datagrad\n",
        "    data_grad = x.grad.data\n",
        "    \n",
        "    # Call sign() on the gradients to get the sign of the gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    \n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = x + epsilon*sign_data_grad\n",
        "    \n",
        "    # Clip the perturbed image to keep it within the range [0,1]\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    \n",
        "    # Return the perturbed image\n",
        "    return perturbed_image\n"
      ],
      "metadata": {
        "id": "P1rsuViyZx8K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate adversarial examples for a subset of the CIFAR-10 dataset using the FGSM attack. You can use different strengths of the attack by adjusting the magnitude of the perturbation."
      ],
      "metadata": {
        "id": "EGl9pg9RZ-MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "NMLF60o3cBvy",
        "outputId": "7fea162a-067a-4489-e82b-0ed5ab968382"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-0cb674e26d9d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "def fgsm_attack(model, loss, x, y, epsilon):\n",
        "    # Generate perturbation\n",
        "    delta = torch.zeros_like(x, requires_grad=True)\n",
        "    loss_val = loss(model(x + delta), y)\n",
        "    loss_val.backward()\n",
        "    delta.data = epsilon * delta.grad.detach().sign()\n",
        "    \n",
        "    # Add perturbation to input\n",
        "    x_adv = x + delta\n",
        "    \n",
        "    # Clip perturbed input to valid range\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    \n",
        "    return x_adv\n",
        "\n",
        "# Define transforms for the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                           download=True, transform=transform)\n",
        "\n",
        "# Define the dataloader\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Set the model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Generate adversarial examples for the first 100 images in the test set\n",
        "epsilon = 0.1\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs.requires_grad = True\n",
        "    \n",
        "    # Generate adversarial examples using FGSM attack\n",
        "    adv_inputs = fgsm_attack(model, criterion, inputs, labels, epsilon)\n",
        "    \n",
        "    # Evaluate accuracy on original and adversarial examples\n",
        "    outputs = model(inputs)\n",
        "    _, pred = torch.max(outputs.data, 1)\n",
        "    correct = (pred == labels).sum().item()\n",
        "    acc = correct / labels.size(0)\n",
        "    \n",
        "    adv_outputs = model(adv_inputs)\n",
        "    _, adv_pred = torch.max(adv_outputs.data, 1)\n",
        "    adv_correct = (adv_pred == labels).sum().item()\n",
        "    adv_acc = adv_correct / labels.size(0)\n",
        "    \n",
        "    print('Batch %d: Original Acc = %.2f%%, Adversarial Acc = %.2f%%' % (i+1, acc*100, adv_acc*100))\n",
        "    \n",
        "    if i == 0:\n",
        "        # Save the original and adversarial examples for visualization\n",
        "        torchvision.utils.save_image(inputs, 'original.png')\n",
        "        torchvision.utils.save_image(adv_inputs, 'adversarial.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJoXtLFaHcx",
        "outputId": "0dd12526-d162-40b4-f9c3-b1d6456102d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: Original Acc = 7.00%, Adversarial Acc = 8.00%\n",
            "Batch 2: Original Acc = 4.00%, Adversarial Acc = 3.00%\n",
            "Batch 3: Original Acc = 6.00%, Adversarial Acc = 6.00%\n",
            "Batch 4: Original Acc = 5.00%, Adversarial Acc = 2.00%\n",
            "Batch 5: Original Acc = 4.00%, Adversarial Acc = 3.00%\n",
            "Batch 6: Original Acc = 5.00%, Adversarial Acc = 5.00%\n",
            "Batch 7: Original Acc = 10.00%, Adversarial Acc = 7.00%\n",
            "Batch 8: Original Acc = 6.00%, Adversarial Acc = 5.00%\n",
            "Batch 9: Original Acc = 8.00%, Adversarial Acc = 2.00%\n",
            "Batch 10: Original Acc = 9.00%, Adversarial Acc = 8.00%\n",
            "Batch 11: Original Acc = 7.00%, Adversarial Acc = 8.00%\n",
            "Batch 12: Original Acc = 4.00%, Adversarial Acc = 7.00%\n",
            "Batch 13: Original Acc = 9.00%, Adversarial Acc = 6.00%\n",
            "Batch 14: Original Acc = 8.00%, Adversarial Acc = 5.00%\n",
            "Batch 15: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 16: Original Acc = 8.00%, Adversarial Acc = 7.00%\n",
            "Batch 17: Original Acc = 6.00%, Adversarial Acc = 6.00%\n",
            "Batch 18: Original Acc = 12.00%, Adversarial Acc = 6.00%\n",
            "Batch 19: Original Acc = 9.00%, Adversarial Acc = 2.00%\n",
            "Batch 20: Original Acc = 6.00%, Adversarial Acc = 5.00%\n",
            "Batch 21: Original Acc = 10.00%, Adversarial Acc = 6.00%\n",
            "Batch 22: Original Acc = 6.00%, Adversarial Acc = 7.00%\n",
            "Batch 23: Original Acc = 7.00%, Adversarial Acc = 6.00%\n",
            "Batch 24: Original Acc = 3.00%, Adversarial Acc = 5.00%\n",
            "Batch 25: Original Acc = 4.00%, Adversarial Acc = 7.00%\n",
            "Batch 26: Original Acc = 5.00%, Adversarial Acc = 3.00%\n",
            "Batch 27: Original Acc = 9.00%, Adversarial Acc = 3.00%\n",
            "Batch 28: Original Acc = 8.00%, Adversarial Acc = 3.00%\n",
            "Batch 29: Original Acc = 8.00%, Adversarial Acc = 5.00%\n",
            "Batch 30: Original Acc = 9.00%, Adversarial Acc = 2.00%\n",
            "Batch 31: Original Acc = 9.00%, Adversarial Acc = 5.00%\n",
            "Batch 32: Original Acc = 7.00%, Adversarial Acc = 3.00%\n",
            "Batch 33: Original Acc = 7.00%, Adversarial Acc = 6.00%\n",
            "Batch 34: Original Acc = 8.00%, Adversarial Acc = 4.00%\n",
            "Batch 35: Original Acc = 7.00%, Adversarial Acc = 6.00%\n",
            "Batch 36: Original Acc = 4.00%, Adversarial Acc = 3.00%\n",
            "Batch 37: Original Acc = 8.00%, Adversarial Acc = 4.00%\n",
            "Batch 38: Original Acc = 11.00%, Adversarial Acc = 10.00%\n",
            "Batch 39: Original Acc = 9.00%, Adversarial Acc = 1.00%\n",
            "Batch 40: Original Acc = 6.00%, Adversarial Acc = 7.00%\n",
            "Batch 41: Original Acc = 6.00%, Adversarial Acc = 4.00%\n",
            "Batch 42: Original Acc = 7.00%, Adversarial Acc = 4.00%\n",
            "Batch 43: Original Acc = 7.00%, Adversarial Acc = 4.00%\n",
            "Batch 44: Original Acc = 3.00%, Adversarial Acc = 1.00%\n",
            "Batch 45: Original Acc = 6.00%, Adversarial Acc = 5.00%\n",
            "Batch 46: Original Acc = 5.00%, Adversarial Acc = 5.00%\n",
            "Batch 47: Original Acc = 8.00%, Adversarial Acc = 3.00%\n",
            "Batch 48: Original Acc = 9.00%, Adversarial Acc = 7.00%\n",
            "Batch 49: Original Acc = 11.00%, Adversarial Acc = 2.00%\n",
            "Batch 50: Original Acc = 10.00%, Adversarial Acc = 8.00%\n",
            "Batch 51: Original Acc = 8.00%, Adversarial Acc = 3.00%\n",
            "Batch 52: Original Acc = 5.00%, Adversarial Acc = 7.00%\n",
            "Batch 53: Original Acc = 6.00%, Adversarial Acc = 2.00%\n",
            "Batch 54: Original Acc = 4.00%, Adversarial Acc = 5.00%\n",
            "Batch 55: Original Acc = 6.00%, Adversarial Acc = 6.00%\n",
            "Batch 56: Original Acc = 9.00%, Adversarial Acc = 5.00%\n",
            "Batch 57: Original Acc = 6.00%, Adversarial Acc = 4.00%\n",
            "Batch 58: Original Acc = 9.00%, Adversarial Acc = 8.00%\n",
            "Batch 59: Original Acc = 5.00%, Adversarial Acc = 7.00%\n",
            "Batch 60: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 61: Original Acc = 4.00%, Adversarial Acc = 2.00%\n",
            "Batch 62: Original Acc = 9.00%, Adversarial Acc = 5.00%\n",
            "Batch 63: Original Acc = 6.00%, Adversarial Acc = 6.00%\n",
            "Batch 64: Original Acc = 6.00%, Adversarial Acc = 3.00%\n",
            "Batch 65: Original Acc = 7.00%, Adversarial Acc = 6.00%\n",
            "Batch 66: Original Acc = 8.00%, Adversarial Acc = 9.00%\n",
            "Batch 67: Original Acc = 9.00%, Adversarial Acc = 5.00%\n",
            "Batch 68: Original Acc = 4.00%, Adversarial Acc = 1.00%\n",
            "Batch 69: Original Acc = 7.00%, Adversarial Acc = 3.00%\n",
            "Batch 70: Original Acc = 4.00%, Adversarial Acc = 3.00%\n",
            "Batch 71: Original Acc = 5.00%, Adversarial Acc = 2.00%\n",
            "Batch 72: Original Acc = 8.00%, Adversarial Acc = 12.00%\n",
            "Batch 73: Original Acc = 9.00%, Adversarial Acc = 7.00%\n",
            "Batch 74: Original Acc = 6.00%, Adversarial Acc = 4.00%\n",
            "Batch 75: Original Acc = 10.00%, Adversarial Acc = 6.00%\n",
            "Batch 76: Original Acc = 7.00%, Adversarial Acc = 2.00%\n",
            "Batch 77: Original Acc = 6.00%, Adversarial Acc = 5.00%\n",
            "Batch 78: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 79: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 80: Original Acc = 9.00%, Adversarial Acc = 4.00%\n",
            "Batch 81: Original Acc = 5.00%, Adversarial Acc = 6.00%\n",
            "Batch 82: Original Acc = 11.00%, Adversarial Acc = 10.00%\n",
            "Batch 83: Original Acc = 6.00%, Adversarial Acc = 3.00%\n",
            "Batch 84: Original Acc = 10.00%, Adversarial Acc = 9.00%\n",
            "Batch 85: Original Acc = 4.00%, Adversarial Acc = 7.00%\n",
            "Batch 86: Original Acc = 7.00%, Adversarial Acc = 5.00%\n",
            "Batch 87: Original Acc = 7.00%, Adversarial Acc = 4.00%\n",
            "Batch 88: Original Acc = 5.00%, Adversarial Acc = 6.00%\n",
            "Batch 89: Original Acc = 9.00%, Adversarial Acc = 4.00%\n",
            "Batch 90: Original Acc = 3.00%, Adversarial Acc = 6.00%\n",
            "Batch 91: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 92: Original Acc = 4.00%, Adversarial Acc = 2.00%\n",
            "Batch 93: Original Acc = 6.00%, Adversarial Acc = 1.00%\n",
            "Batch 94: Original Acc = 10.00%, Adversarial Acc = 6.00%\n",
            "Batch 95: Original Acc = 5.00%, Adversarial Acc = 4.00%\n",
            "Batch 96: Original Acc = 6.00%, Adversarial Acc = 3.00%\n",
            "Batch 97: Original Acc = 8.00%, Adversarial Acc = 9.00%\n",
            "Batch 98: Original Acc = 5.00%, Adversarial Acc = 5.00%\n",
            "Batch 99: Original Acc = 11.00%, Adversarial Acc = 5.00%\n",
            "Batch 100: Original Acc = 4.00%, Adversarial Acc = 4.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "def fgsm_attack(model, loss, x, y, epsilon):\n",
        "    x = torch.tensor(x, requires_grad=True)\n",
        "    # Generate perturbation\n",
        "    delta = torch.zeros_like(x, requires_grad=True)\n",
        "    torch.set_grad_enabled(True)  # Context-manager \n",
        "    loss_val = loss(model(x + delta), y)\n",
        "    loss_val.backward()\n",
        "    delta.data = epsilon * delta.grad.detach().sign()\n",
        "    \n",
        "    # Add perturbation to input\n",
        "    x_adv = x + delta\n",
        "    \n",
        "    # Clip perturbed input to valid range\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    \n",
        "    return x_adv\n",
        "\n",
        "# Define transforms for the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                           download=True, transform=transform)\n",
        "\n",
        "# Define the dataloader\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set the model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# Define the loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Generate adversarial examples for the test set\n",
        "epsilon = 0.1\n",
        "total = 0\n",
        "correct = 0\n",
        "adv_correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Evaluate accuracy on original examples\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        \n",
        "        # Generate adversarial examples using FGSM attack\n",
        "        adv_inputs = fgsm_attack(model, criterion, inputs, labels, epsilon)\n",
        "        adv_inputs = adv_inputs.to(device)\n",
        "        \n",
        "        # Evaluate accuracy on adversarial examples\n",
        "        adv_outputs = model(adv_inputs)\n",
        "        _, adv_pred = torch.max(adv_outputs.data, 1)\n",
        "        adv_correct += (adv_pred == labels).sum().item()\n",
        "        \n",
        "        total += labels.size(0)\n",
        "    \n",
        "    # Print accuracy on original and adversarial examples\n",
        "    acc = 100 * correct / total\n",
        "    adv_acc = 100 * adv_correct / total\n",
        "    print('Original Acc = %.2f%%, Adversarial Acc = %.2f%%' % (acc, adv_acc))\n",
        "    \n",
        "    # Save the original and adversarial examples for visualization\n",
        "   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zsgL1fWdUKM",
        "outputId": "5aa9714c-23dc-459a-b0e5-0cd8000712f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a4ee0be1f79d>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Acc = 8.39%, Adversarial Acc = 7.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate adversarial examples for the test set\n",
        "epsilon = 0.1\n",
        "total = 0\n",
        "correct = 0\n",
        "adv_correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Evaluate accuracy on original examples\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        \n",
        "        # Set the requires_grad flag to True for the input tensor\n",
        "        inputs.requires_grad = True\n",
        "        \n",
        "        # Generate adversarial examples using FGSM attack\n",
        "        adv_inputs = fgsm_attack(model, criterion, inputs, labels, epsilon)\n",
        "        adv_inputs = adv_inputs.to(device)\n",
        "        \n",
        "        # Evaluate accuracy on adversarial examples\n",
        "        adv_outputs = model(adv_inputs)\n",
        "        _, adv_pred = torch.max(adv_outputs.data, 1)\n",
        "        adv_correct += (adv_pred == labels).sum().item()\n",
        "        \n",
        "        total += labels.size(0)\n",
        "    \n",
        "    # Print accuracy on original and adversarial examples\n",
        "    acc = 100 * correct / total\n",
        "    adv_acc = 100 * adv_correct / total\n",
        "    print('Original Acc = %.2f%%, Adversarial Acc = %.2f%%' % (acc, adv_acc))\n",
        "    \n",
        "    # Save the original and adversarial examples for visualization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "KYHd3JrIe7mo",
        "outputId": "5c86db64-780f-4e53-a1f8-b357a06a317a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9d3b9083f90d>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0fd37d7ab7af>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Generate adversarial examples using FGSM attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0madv_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0madv_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9d3b9083f90d>\u001b[0m in \u001b[0;36mfgsm_attack\u001b[0;34m(model, loss, x, y, epsilon)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwyS+ac7SoDIdy0ZHChaLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}